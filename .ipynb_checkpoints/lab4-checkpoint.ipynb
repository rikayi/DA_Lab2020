{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fully connected neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.csv')\n",
    "df = df.drop('fnlwgt',axis=1)\n",
    "df = df.replace('?', np.NaN)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['workclass'] = pd.Categorical(df['workclass'])\n",
    "df['education'] = pd.Categorical(df['education'])\n",
    "df['marital-status'] = pd.Categorical(df['marital-status'])\n",
    "df['occupation'] = pd.Categorical(df['occupation'])\n",
    "df['relationship'] = pd.Categorical(df['relationship'])\n",
    "df['race'] = pd.Categorical(df['race'])\n",
    "df['gender'] = pd.Categorical(df['gender'])\n",
    "df['native-country'] = pd.Categorical(df['native-country'])\n",
    "df['income'] = pd.Categorical(df['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.select_dtypes(include='category').columns:\n",
    "    if column=='income':\n",
    "        continue\n",
    "    df = pd.concat([df, pd.get_dummies(df[column], prefix=column)],axis=1)\n",
    "    df.drop([column],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('income',axis=1), df['income'].cat.codes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.select_dtypes(include='int64').columns:\n",
    "    scale = StandardScaler().fit(X_train[[column]])\n",
    "    X_train[[column]] = scale.transform(X_train[[column]])\n",
    "    X_test[[column]] = scale.transform(X_test[[column]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=103, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3690 - accuracy: 0.8281\n",
      "Epoch 2/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3358 - accuracy: 0.8515\n",
      "Epoch 3/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3266 - accuracy: 0.8527\n",
      "Epoch 4/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3211 - accuracy: 0.8536\n",
      "Epoch 5/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3172 - accuracy: 0.8545\n",
      "Epoch 6/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3138 - accuracy: 0.8573\n",
      "Epoch 7/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3114 - accuracy: 0.8574\n",
      "Epoch 8/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3092 - accuracy: 0.8577\n",
      "Epoch 9/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3070 - accuracy: 0.8597\n",
      "Epoch 10/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3056 - accuracy: 0.8596\n",
      "Epoch 11/25\n",
      "1131/1131 [==============================] - 1s 994us/step - loss: 0.3036 - accuracy: 0.8600\n",
      "Epoch 12/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.3025 - accuracy: 0.8602\n",
      "Epoch 13/25\n",
      "1131/1131 [==============================] - 1s 959us/step - loss: 0.3010 - accuracy: 0.8612\n",
      "Epoch 14/25\n",
      "1131/1131 [==============================] - 1s 956us/step - loss: 0.2996 - accuracy: 0.8614\n",
      "Epoch 15/25\n",
      "1131/1131 [==============================] - 1s 952us/step - loss: 0.2984 - accuracy: 0.8626\n",
      "Epoch 16/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.2980 - accuracy: 0.8623\n",
      "Epoch 17/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.2964 - accuracy: 0.8625\n",
      "Epoch 18/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.2950 - accuracy: 0.8636: 0s - loss: 0.2958 - accu\n",
      "Epoch 19/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.2950 - accuracy: 0.8646\n",
      "Epoch 20/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.2933 - accuracy: 0.8636\n",
      "Epoch 21/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.2930 - accuracy: 0.8646\n",
      "Epoch 22/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.2919 - accuracy: 0.8655\n",
      "Epoch 23/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.2912 - accuracy: 0.8659\n",
      "Epoch 24/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.2901 - accuracy: 0.8659\n",
      "Epoch 25/25\n",
      "1131/1131 [==============================] - 1s 1ms/step - loss: 0.2900 - accuracy: 0.8655: 0s - loss: 0.2889 - ac\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1062115c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)> 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6873485215705283"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      6842\n",
      "           1       0.74      0.64      0.69      2203\n",
      "\n",
      "    accuracy                           0.86      9045\n",
      "   macro avg       0.81      0.78      0.80      9045\n",
      "weighted avg       0.85      0.86      0.85      9045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6337  505]\n",
      " [ 785 1418]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN lost to AdaBoost and GBoost but outperformed all other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN - in file 2_CNN.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout, GlobalMaxPooling1D, SimpleRNN\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('clickbait_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25600,) (6400,)\n"
     ]
    }
   ],
   "source": [
    "text = data['headline'].values\n",
    "labels = data['clickbait'].values\n",
    "text_train, text_test, y_train, y_test = train_test_split(text, labels, test_size=0.2, random_state=42)\n",
    "print(text_train.shape, text_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.headline.str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "maxlen = 135\n",
    "embedding_size = 32\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(text_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(text_train)\n",
    "x_test = tokenizer.texts_to_sequences(text_test)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 135, 32)           160000    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 135, 32)           2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 162,113\n",
      "Trainable params: 162,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=maxlen))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 0.6013 - accuracy: 0.7657 - val_loss: 0.4521 - val_accuracy: 0.9034\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3513 - accuracy: 0.9214 - val_loss: 0.2605 - val_accuracy: 0.9458\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 0.2027 - accuracy: 0.9605 - val_loss: 0.1675 - val_accuracy: 0.9606\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.1298 - accuracy: 0.9731 - val_loss: 0.1258 - val_accuracy: 0.9650\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 5s 98ms/step - loss: 0.0902 - accuracy: 0.9811 - val_loss: 0.1070 - val_accuracy: 0.9684\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size=512, validation_data=(x_test, y_test), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 96.84%\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x_test)>0.5\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
